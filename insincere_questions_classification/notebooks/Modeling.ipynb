{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeExtraChars(qtext):\n",
    "    result = [re.sub(r'[^A-Za-z ]+', ' ', sentence) for sentence in qtext]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(qtext):\n",
    "    # Remove stop words\n",
    "    result = []\n",
    "    for sentence in qtext:\n",
    "        words = sentence.split()\n",
    "        result.append(' '.join([w for w in words if w not in STOPWORDS]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessText(df):\n",
    "    \n",
    "    # Remove extra characters\n",
    "    df['question_text'] = removeExtraChars(df['question_text'])\n",
    "    \n",
    "    # Lower case\n",
    "    df['question_text'] = [sentence.lower() for sentence in df['question_text']]\n",
    "    \n",
    "    # Remove stop words\n",
    "    df['question_text'] = removeStopWords(df['question_text'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessTextTransformer():\n",
    "    \n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocessTextTransformer(preprocessText))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pipeline.fit_transform(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def tokenize(sentence):\n",
    "#    tokens = [word for word in nltk.word_tokenize(sentence) if len(word)>1]\n",
    "#    stemmer = PorterStemmer()\n",
    "#    stems = [stemmer.stem(item) for item in tokens]\n",
    "#    return stems\n",
    "\n",
    "#def createDTM(qtext):\n",
    "#    vectorizer = TfidfVectorizer(tokenizer = tokenize)\n",
    "#    dtm = vectorizer.fit_transform(qtext)\n",
    "#    result = pd.DataFrame(dtm.toarray(), columns=vectorizer.get_feature_names())\n",
    "#    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pipeline.fit_transform(trainData['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "sdf = pd.DataFrame.sparse.from_spmatrix(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
